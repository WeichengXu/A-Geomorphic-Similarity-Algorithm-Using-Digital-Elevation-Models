from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.colors as mcolors
from matplotlib.cm import ScalarMappable
from collections import Counter
import rasterio


def crop_tif(tif_path, row_start, row_end, col_start, col_end):
    """
    Crops a TIFF image and returns the cropped matrix.
    """
    image = Image.open(tif_path).convert('L')
    image_matrix = np.array(image)
    return image_matrix[row_start:row_end, col_start:col_end]


def get_neighbor_pairs(grid):
    """
    Computes squared sums of each cell with its neighbors in a grid.
    """
    # Map grayscale values to integers for easier calculations
    mapping = {6: 1, 17: 2, 29: 3, 60: 4, 125: 5, 182: 6, 191: 7, 105: 8, 220: 9, 233: 10}
    for original, new in mapping.items():
        grid[grid == original] = new

    rows, cols = grid.shape
    pairs = []

    # Define neighbor directions
    directions = [(-1, 0), (1, 0), (0, -1), (0, 1), (-1, -1), (-1, 1), (1, -1), (1, 1)]
    for row in range(rows):
        for col in range(cols):
            for d_row, d_col in directions:
                n_row, n_col = row + d_row, col + d_col
                if 0 <= n_row < rows and 0 <= n_col < cols:
                    pairs.append(grid[row, col]**2 + grid[n_row, n_col]**2)
    return pairs


def value_counter(grid):
    """
    Counts occurrences of squared sums of cell values and their neighbors.
    """
    number_list = get_neighbor_pairs(grid)
    square_sums = [i**2 + j**2 for i in range(1, 11) for j in range(i, 11)]
    counter = Counter(number_list)
    return {val: counter.get(val, 0) for val in square_sums}


def wave_hedges_similarity(A, B):
    """
    Computes the Wave Hedges similarity index between two arrays.
    """
    A, B = np.array(A), np.array(B)
    if A.shape != B.shape:
        raise ValueError("Input arrays must have the same shape.")
    numerator = np.abs(A - B)
    denominator = np.maximum(A, B)
    non_zero = denominator != 0
    similarity_sum = np.sum(numerator[non_zero] / denominator[non_zero])
    return 1 - similarity_sum / len(A)


def similarity_index_for_matrix(tif_path, target_matrix, block_size, threshold):
    """
    Computes the similarity index for each block compared to the target matrix.
    """
    image = Image.open(tif_path).convert('L')
    image_matrix = np.array(image)
    rows, cols = image_matrix.shape
    block_list = [
        image_matrix[row:row + block_size, col:col + block_size]
        for row in range(0, rows, block_size)
        for col in range(0, cols, block_size)
        if image_matrix[row:row + block_size, col:col + block_size].shape == (block_size, block_size)
    ]
    target_counts = list(value_counter(target_matrix).values())
    similar_blocks = sum(
        wave_hedges_similarity(target_counts, list(value_counter(block).values())) >= threshold
        for block in block_list
    )
    return similar_blocks / len(block_list)


def combined_similarity_plot(tif_path, block_size, threshold, alpha):
    """
    Generates a combined similarity plot with an overlay of the original image.
    """
    # Load base image and prepare for overlay
    base_image = Image.open(tif_path).convert('RGBA')

    # Generate similarity map
    image = Image.open(tif_path).convert('L')
    image_matrix = np.array(image)
    rows, cols = image_matrix.shape
    block_list = [
        image_matrix[row:row + block_size, col:col + block_size]
        for row in range(0, rows, block_size)
        for col in range(0, cols, block_size)
    ]
    similarity_indices = [
        similarity_index_for_matrix(tif_path, block, block_size, threshold)
        for block in block_list
    ]
    similarity_map = np.zeros((rows, cols), dtype=float)
    for idx, block in enumerate(block_list):
        row_start = (idx // (cols // block_size)) * block_size
        col_start = (idx % (cols // block_size)) * block_size
        similarity_map[row_start:row_start + block_size, col_start:col_start + block_size] = similarity_indices[idx]

    # Apply colormap
    colormap = cm.get_cmap('coolwarm')
    colored_array = colormap(similarity_map)
    overlay_image = Image.fromarray((colored_array[:, :, :3] * 255).astype(np.uint8)).convert('RGBA')

    # Adjust alpha for overlay
    r, g, b, a = overlay_image.split()
    a = a.point(lambda p: int(p * alpha))
    overlay_image.putalpha(a)

    # Composite images
    combined_image = Image.alpha_composite(base_image, overlay_image)
    combined_image.show()
    return combined_image


def lower_resolution_tif(input_tif_path, output_tif_path, scale_factor):
    """
    Reduces the resolution of a TIFF image and saves the result.
    """
    image = Image.open(input_tif_path)
    new_width, new_height = image.width // scale_factor, image.height // scale_factor
    resized_image = image.resize((new_width, new_height), Image.LANCZOS)
    resized_image.save(output_tif_path, format='TIFF')


# Example usage
if __name__ == "__main__":
    tif_path = "/path/to/your/input.tif"  # Replace with your file path
    output_tif = "/path/to/your/output.tif"  # Replace with desired output path
    block_size = 20
    threshold = 0.8
    alpha = 0.7

    # Generate and save the combined similarity plot
    combined_image = combined_similarity_plot(tif_path, block_size, threshold, alpha)
    combined_image.save(output_tif, format="TIFF")
